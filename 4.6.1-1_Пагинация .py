# https://stepik.org/lesson/700334/step/1?unit=700275
# Пагинация
# Пагинация (от слова page - “страница”) повсюду, нам приходится работать с ней почти всегда при написании парсера.
# В этом блоке мы изучим пагинацию, научимся проходиться по ней в цикле и извлекать информацию на каждой странице.
#
# В нашем тренажере она тоже есть = http://parsinger.ru/legal/html/index1_page_1.html. На скриншоте выделено 2 области.
# В верхней области мы видим ссылку, которая заканчивается числом, как правило, число = номер страницы.
# Мы можем изменить ссылку и делать запросы на каждой итерации. Во второй области выделены кнопки пагинации.
#
# В нашем тренажере простая пагинация, она имеет всего 4 страницы, но это достаточно для понимания.
# Итак, для начала нам необходимо получить общее количество страниц.  В этом нам помогает пагинация.
# Давайте посмотрим на HTML код пагинации.
# Мы видим, что здесь она представляет собой блок <div class='pagen'> , в котором 4 тега <a>.
# Мы уже умеем пользоваться методами .find() и .find_all() , давайте применим их и соберем ссылки из пагинации,
# также нам понадобится значение последнего элемента.
from bs4 import BeautifulSoup
import requests

url = 'http://parsinger.ru/html/index1_page_3.html'
response = requests.get(url=url)
response.encoding = 'utf-8'
soup = BeautifulSoup(response.text, 'lxml')
pagen = soup.find('div', class_='pagen').find_all('a')
print(pagen)

# >>> [<a href="index1_page_1.html">1</a>, <a href="index1_page_2.html">2</a>, <a href="index1_page_3.html">3</a>,
# <a href="index1_page_4.html">4</a>]
# Мы получили список тегов,  но нам ведь нужно извлечь ссылку и текст.
# Применим list comprehension, чтобы сделать это удобнее.
pagen = [link['href'] for link in soup.find('div', class_='pagen').find_all('a')]
print(pagen)
# >>> ['index1_page_1.html', 'index1_page_2.html', 'index1_page_3.html', 'index1_page_4.html']
# Обратите внимание на то, как мы получаем значение атрибута href='', подобным образом мы можем извлекать ссылку
# из тегов <a>. Такой подход  применим и к тегу <img>, мы сможем извлечь src='',  где хранится ссылка на изображение.
# Картинки мы будем парсить в следующих уроках.
#
# Итак, что мы имеем? А имеем мы список, в котором хранятся 4 имени файла, и нужно превратить их в ссылки.
# Вероятно, вы уже догадались, как это сделать. Если вы предположили, что это будет f''-строка, то вы совершенно правы.
#
# Давайте проанализируем, как формируется ссылка на пагинацию, и сформируем схему, которая поможет генерировать
# корректные ссылки.
#
# За схемой далеко ходить не нужно, в адресной строке мы можем ее увидеть.
# stepik-parsing.ru/html/index1_page_3.html
